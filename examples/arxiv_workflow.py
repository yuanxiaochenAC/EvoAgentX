import os 
from dotenv import load_dotenv
from evoagentx.models import OpenAILLMConfig, OpenAILLM
from evoagentx.workflow import WorkFlowGenerator, WorkFlowGraph, WorkFlow
from evoagentx.agents import AgentManager
from evoagentx.tools.file_tool import FileToolkit
from evoagentx.tools import ArxivToolkit   # å¼•å…¥ Arxiv å·¥å…·

load_dotenv()  # åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")


def main():
    # åˆå§‹åŒ–å¤§æ¨¡å‹é…ç½®
    openai_config = OpenAILLMConfig(
        model="gpt-4o",
        openai_key=OPENAI_API_KEY,
        stream=True,
        output_response=True,
        max_tokens=16000
    )
    llm = OpenAILLM(config=openai_config)

    # è®¾ç½®æ–‡çŒ®å…³é”®è¯ï¼Œæ¨é€æ–‡çŒ®æ•°é‡ï¼Œæ–‡çŒ®æ—¥æœŸï¼Œæ–‡çŒ®åˆ†ç±»
    keywords = "medical, multiagent"
    max_results = 10
    date_from = "2024-01-01"
    categories = ["cs.AI", "cs.LG"]

    # æ„å»ºæœç´¢æ¡ä»¶æè¿°
    search_constraints = f"""
    Search constraints:
    - Query keywords: {keywords}
    - Max results: {max_results}
    - Date from: {date_from}
    - Categories: {', '.join(categories)}
    """

    # åŠ©æ‰‹çš„ç›®æ ‡ä»»åŠ¡
    goal = f"""Create a daily research paper recommendation assistant that takes user keywords and pushes new relevant papers with summaries.

    The assistant should:
    1. Use the ArxivToolkit to search for the latest papers using the given keywords.
    2. Apply the following search constraints:
    {search_constraints}
    3. Summarize the search results.
    4. Compile the summaries into a well-formatted Markdown digest.

    ### Output
    daily_paper_digest
    """

    target_directory = "EvoAgentX/examples/output/paper_push"
    module_save_path = os.path.join(target_directory, "paper_push_workflow.json")
    result_path = os.path.join(target_directory, "daily_paper_digest.md")
    os.makedirs(target_directory, exist_ok=True)

    # âœ… åˆå§‹åŒ– Arxiv å·¥å…·
    arxiv_toolkit = ArxivToolkit()
    tools = [arxiv_toolkit, FileToolkit()]

    # ç”Ÿæˆå·¥ä½œæµå›¾
    wf_generator = WorkFlowGenerator(llm=llm, tools=tools)
    workflow_graph: WorkFlowGraph = wf_generator.generate_workflow(goal=goal)

    # ä¿å­˜ç”Ÿæˆçš„å·¥ä½œæµæ¨¡å—
    workflow_graph.save_module(module_save_path)

    # å±•ç¤ºå¯è§†åŒ–ç»“æ„
    workflow_graph.display()

    # Agent ç®¡ç†å™¨åˆå§‹åŒ–
    agent_manager = AgentManager(tools=tools)
    agent_manager.add_agents_from_workflow(workflow_graph, llm_config=openai_config)

    # æ„å»ºä¸æ‰§è¡Œå®Œæ•´å·¥ä½œæµ
    workflow = WorkFlow(graph=workflow_graph, agent_manager=agent_manager, llm=llm)
    output = workflow.execute()

    # ä¿å­˜æ‘˜è¦ç»“æœä¸º Markdown
    with open(result_path, "w", encoding="utf-8") as f:
        f.write(output)

    print(f"âœ… æ¨é€ç»“æœå·²ä¿å­˜åˆ°ï¼š{result_path}")
    print("ğŸ“¬ ä½ å¯ä»¥è®¾ç½®å®šæ—¶ä»»åŠ¡æ¯å¤©è‡ªåŠ¨è¿è¡Œæ­¤è„šæœ¬æ¥è·å–æ¨è")


if __name__ == "__main__":
    main()
